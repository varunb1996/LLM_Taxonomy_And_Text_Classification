{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf61ae-4d1a-49fb-b8fe-e7e39c9f3d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langgraph langchain langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6a894-c0f3-45f5-b9d1-992d9e2f07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export AZURE_OPENAI_API_KEY='your_api_key_here' export AZURE_OPENAI_MODEL='your_deployment_name_here' export AZURE_OPENAI_ENDPOINT='deployment_endpoint'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2cf5d-5a7d-4c7d-85b1-e7bd8df1362a",
   "metadata": {},
   "source": [
    "BUILDING A SIMPLE TNT-LLM APPLICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf0a9ee-761d-49a5-bba2-c28139669a92",
   "metadata": {},
   "source": [
    " Define graph state class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f24ede-a408-4102-b1ae-d8973ff08ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, List, TypedDict, Optional\n",
    "class Doc(TypedDict):\n",
    "    id: str\n",
    "    content: str\n",
    "    summary: Optional[str]\n",
    "    explanation: Optional[str]\n",
    "    category: Optional[str]\n",
    "class TaxonomyGenerationState(TypedDict):\n",
    "    # The raw docs; we inject summaries within them in the first step\n",
    "    documents: List[Doc]\n",
    "    # Indices to be concise\n",
    "    minibatches: List[List[int]]\n",
    "    # Candidate Taxonomies (full trajectory)\n",
    "    clusters: Annotated[List[List[dict]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235fd67-952e-4075-a4ad-3ea268559410",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436b76b-4691-45ed-a780-cdb0ed80c605",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"okite97/news-data\")\n",
    "# Access the different splits if available (e.g., train, test, validation)\n",
    "train_data = dataset['train']\n",
    "df = pd.DataFrame(train_data)\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "def run_to_doc(df: pd.DataFrame) -> Doc:\n",
    "    all_data = []\n",
    "    for i in range(len(df)):\n",
    "        d = df.iloc[i]\n",
    "        all_data.append({\n",
    "            \"id\": i,\n",
    "            \"content\": d['Title'] + \"\\\\n\\\\n\" + d['Excerpt']\n",
    "        })\n",
    "    \n",
    "    return all_data\n",
    "# Only clustering 100 documents\n",
    "docs = run_to_doc(df[:100])\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da93a7-b17d-40f4-8cc0-e48b1cbd87a4",
   "metadata": {},
   "source": [
    "{'id': 0,\n",
    " 'content': 'Uefa Opens Proceedings against Barcelona, Juventus and Real Madrid Over European Super League Plan\\\\n\\\\nUefa has opened disciplinary proceedings against Barcelona, Juventus and Real Madrid over their involvement in the proposed European Super League.'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5254e02-9f1a-4995-ba68-eb474f934652",
   "metadata": {},
   "source": [
    "Initialize Azure-based OpenAI GPT-4o model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9844261-1292-43d4-b040-5ecc83b3ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "model = AzureChatOpenAI(\n",
    "    openai_api_version=\"2023-06-01-preview\"\n",
    "    azure_deployment=\"gpt-4o-2024-05-13\",\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb35297-e842-486f-ad51-bf94ab83e7bc",
   "metadata": {},
   "source": [
    "Summarize documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a5b9a-0af5-4aa3-9acc-1da59248239e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda, RunnablePassthrough\n",
    "summary_prompt = hub.pull(\"wfh/tnt-llm-summary-generation\").partial(\n",
    "    summary_length=20, explanation_length=30\n",
    ")\n",
    "def parse_summary(xml_string: str) -> dict:\n",
    "    summary_pattern = r\"<summary>(.*?)</summary>\"\n",
    "    explanation_pattern = r\"<explanation>(.*?)</explanation>\"\n",
    "    summary_match = re.search(summary_pattern, xml_string, re.DOTALL)\n",
    "    explanation_match = re.search(explanation_pattern, xml_string, re.DOTALL)\n",
    "    summary = summary_match.group(1).strip() if summary_match else \"\"\n",
    "    explanation = explanation_match.group(1).strip() if explanation_match else \"\"\n",
    "    return {\"summary\": summary, \"explanation\": explanation}\n",
    "summary_llm_chain = (\n",
    "    summary_prompt | model | StrOutputParser()\n",
    ").with_config(run_name=\"GenerateSummary\")\n",
    "summary_chain = summary_llm_chain | parse_summary\n",
    "# Input: state\n",
    "# Output: state and summaries\n",
    "# Processes docs in parallel\n",
    "def get_content(state: TaxonomyGenerationState):\n",
    "    docs = state[\"documents\"]\n",
    "    return [{\"content\": doc[\"content\"]} for doc in docs]\n",
    "map_step = RunnablePassthrough.assign(\n",
    "    summaries=get_content\n",
    "    | RunnableLambda(func=summary_chain.batch, afunc=summary_chain.abatch)\n",
    ")\n",
    "def reduce_summaries(combined: dict) -> TaxonomyGenerationState:\n",
    "    summaries = combined[\"summaries\"]\n",
    "    documents = combined[\"documents\"]\n",
    "    return {\n",
    "        \"documents\": [\n",
    "            {\n",
    "                \"id\": doc[\"id\"],\n",
    "                \"content\": doc[\"content\"],\n",
    "                \"summary\": summ_info[\"summary\"],\n",
    "                \"explanation\": summ_info[\"explanation\"],\n",
    "            }\n",
    "            for doc, summ_info in zip(documents, summaries)\n",
    "        ]\n",
    "    }\n",
    "# This is the summary node\n",
    "map_reduce_chain = map_step | reduce_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59e5c7e-d4eb-4975-859d-656a65c451e0",
   "metadata": {},
   "source": [
    "Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22974acc-f187-4722-a909-1c0e2b3576a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatches(state: TaxonomyGenerationState, config: RunnableConfig):\n",
    "    batch_size = config[\"configurable\"].get(\"batch_size\", 200)\n",
    "    original = state[\"documents\"]\n",
    "    indices = list(range(len(original)))\n",
    "    random.shuffle(indices)\n",
    "    if len(indices) < batch_size:\n",
    "        # Don't pad needlessly if we can't fill a single batch\n",
    "        return [indices]\n",
    "    num_full_batches = len(indices) // batch_size\n",
    "    batches = [\n",
    "        indices[i * batch_size : (i + 1) * batch_size] for i in range(num_full_batches)\n",
    "    ]\n",
    "    leftovers = len(indices) % batch_size\n",
    "    if leftovers:\n",
    "        last_batch = indices[num_full_batches * batch_size :]\n",
    "        elements_to_add = batch_size - leftovers\n",
    "        last_batch += random.sample(indices, elements_to_add)\n",
    "        batches.append(last_batch)\n",
    "    return {\n",
    "        \"minibatches\": batches,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e1f38-0ade-4beb-a4fb-41cb16cd8aa4",
   "metadata": {},
   "source": [
    "Generate Initial Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba7c4c-6bdc-4f66-bddf-a09eaf7d6142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from langchain_core.runnables import Runnable\n",
    "def parse_taxa(output_text: str) -> Dict:\n",
    "    \"\"\"Extract the taxonomy from the generated output.\"\"\"\n",
    "    cluster_pattern = r\"<cluster>\\\\s*<id>(.*?)</id>\\\\s*<name>(.*?)</name>\\\\s*<description>(.*?)</description>\\\\s*</cluster>\"\n",
    "    cluster_matches = re.findall(cluster_pattern, output_text, re.DOTALL)\n",
    "    clusters = [\n",
    "        {\"id\": id.strip(), \"name\": name.strip(), \"description\": description.strip()}\n",
    "        for id, name, description in cluster_matches\n",
    "    ]\n",
    "    return {\"clusters\": clusters}\n",
    "def format_docs(docs: List[Doc]) -> str:\n",
    "    xml_table = \"\\\\n\"\n",
    "    for doc in docs:\n",
    "        xml_table += f'{doc[\"summary\"]}\\\\n'\n",
    "    xml_table += \"\"\n",
    "    return xml_table\n",
    "def format_taxonomy(clusters):\n",
    "    xml = \"\\\\n\"\n",
    "    for label in clusters:\n",
    "        xml += \"  \\\\n\"\n",
    "        xml += f'    {label[\"id\"]}\\\\n'\n",
    "        xml += f'    {label[\"name\"]}\\\\n'\n",
    "        xml += f'    {label[\"description\"]}\\\\n'\n",
    "        xml += \"  \\\\n\"\n",
    "    xml += \"\"\n",
    "    return xml\n",
    "def invoke_taxonomy_chain(\n",
    "    chain: Runnable,\n",
    "    state: TaxonomyGenerationState,\n",
    "    config: RunnableConfig,\n",
    "    mb_indices: List[int],\n",
    ") -> TaxonomyGenerationState:\n",
    "    configurable = config[\"configurable\"]\n",
    "    docs = state[\"documents\"]\n",
    "    minibatch = [docs[idx] for idx in mb_indices]\n",
    "    data_table_xml = format_docs(minibatch)\n",
    "    previous_taxonomy = state[\"clusters\"][-1] if state[\"clusters\"] else []\n",
    "    cluster_table_xml = format_taxonomy(previous_taxonomy)\n",
    "    updated_taxonomy = chain.invoke(\n",
    "        {\n",
    "            \"data_xml\": data_table_xml,\n",
    "            \"use_case\": configurable[\"use_case\"],\n",
    "            \"cluster_table_xml\": cluster_table_xml,\n",
    "            \"suggestion_length\": configurable.get(\"suggestion_length\", 30),\n",
    "            \"cluster_name_length\": configurable.get(\"cluster_name_length\", 10),\n",
    "            \"cluster_description_length\": configurable.get(\n",
    "                \"cluster_description_length\", 30\n",
    "            ),\n",
    "            \"explanation_length\": configurable.get(\"explanation_length\", 20),\n",
    "            \"max_num_clusters\": configurable.get(\"max_num_clusters\", 25),\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"clusters\": [updated_taxonomy[\"clusters\"]],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cabba4f-30cb-450d-bc2d-abfbb73bc36c",
   "metadata": {},
   "source": [
    "Language model integration into taxonomy generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767dcd4-16e6-4e13-82f4-4d804053a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will share an LLM for each step of the generate -> update -> review cycle\n",
    "# You may want to consider using Opus or another more powerful model for this\n",
    "taxonomy_generation_llm = model\n",
    "## Initial generation\n",
    "taxonomy_generation_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-generation\").partial(\n",
    "    use_case=\"Generate the taxonomy that can be used to label the user intent in the conversation.\",\n",
    ")\n",
    "taxa_gen_llm_chain = (\n",
    "    taxonomy_generation_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name=\"GenerateTaxonomy\")\n",
    "generate_taxonomy_chain = taxa_gen_llm_chain | parse_taxa\n",
    "def generate_taxonomy(\n",
    "    state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    return invoke_taxonomy_chain(\n",
    "        generate_taxonomy_chain, state, config, state[\"minibatches\"][0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97362d40-4bad-4449-afec-be202ffed932",
   "metadata": {},
   "source": [
    "Update taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6c362d-9bb6-47e1-884d-7d7916e65335",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_update_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-update\")\n",
    "taxa_update_llm_chain = (\n",
    "    taxonomy_update_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name=\"UpdateTaxonomy\")\n",
    "update_taxonomy_chain = taxa_update_llm_chain | parse_taxa\n",
    "def update_taxonomy(\n",
    "    state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    which_mb = len(state[\"clusters\"]) % len(state[\"minibatches\"])\n",
    "    return invoke_taxonomy_chain(\n",
    "        update_taxonomy_chain, state, config, state[\"minibatches\"][which_mb]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2998e0-a061-45ad-ba82-0e4d36107484",
   "metadata": {},
   "source": [
    "Review taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5200ead1-f07b-412c-8cf7-b15f403d8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy_review_prompt = hub.pull(\"wfh/tnt-llm-taxonomy-review\")\n",
    "taxa_review_llm_chain = (\n",
    "    taxonomy_review_prompt | taxonomy_generation_llm | StrOutputParser()\n",
    ").with_config(run_name=\"ReviewTaxonomy\")\n",
    "review_taxonomy_chain = taxa_review_llm_chain | parse_taxa\n",
    "def review_taxonomy(\n",
    "    state: TaxonomyGenerationState, config: RunnableConfig\n",
    ") -> TaxonomyGenerationState:\n",
    "    batch_size = config[\"configurable\"].get(\"batch_size\", 200)\n",
    "    original = state[\"documents\"]\n",
    "    indices = list(range(len(original)))\n",
    "    random.shuffle(indices)\n",
    "    return invoke_taxonomy_chain(\n",
    "        review_taxonomy_chain, state, config, indices[:batch_size]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb35b8-331f-44e8-96d8-14e1254466a2",
   "metadata": {},
   "source": [
    "Orchestrating the TNT-LLM pipeline with StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c54e68-043f-45f7-a265-f8f87ef09f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "graph = StateGraph(TaxonomyGenerationState)\n",
    "graph.add_node(\"summarize\", map_reduce_chain)\n",
    "graph.add_node(\"get_minibatches\", get_minibatches)\n",
    "graph.add_node(\"generate_taxonomy\", generate_taxonomy)\n",
    "graph.add_node(\"update_taxonomy\", update_taxonomy)\n",
    "graph.add_node(\"review_taxonomy\", review_taxonomy)\n",
    "graph.add_edge(\"summarize\", \"get_minibatches\")\n",
    "graph.add_edge(\"get_minibatches\", \"generate_taxonomy\")\n",
    "graph.add_edge(\"generate_taxonomy\", \"update_taxonomy\")\n",
    "def should_review(state: TaxonomyGenerationState) -> str:\n",
    "    num_minibatches = len(state[\"minibatches\"])\n",
    "    num_revisions = len(state[\"clusters\"])\n",
    "    if num_revisions < num_minibatches:\n",
    "        return \"update_taxonomy\"\n",
    "    return \"review_taxonomy\"\n",
    "graph.add_conditional_edges(\n",
    "    \"update_taxonomy\",\n",
    "    should_review,\n",
    "    # Optional (but required for the diagram to be drawn correctly below)\n",
    "    {\"update_taxonomy\": \"update_taxonomy\", \"review_taxonomy\": \"review_taxonomy\"},\n",
    ")\n",
    "graph.set_finish_point(\"review_taxonomy\")\n",
    "graph.set_entry_point(\"summarize\")\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56333a-d4db-4818-a73d-9bc65cad8fd7",
   "metadata": {},
   "source": [
    "A sequential graph is generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203fc81-b302-4fce-befc-9d3d1a54c0a9",
   "metadata": {},
   "source": [
    "Clustering and Displaying TNT-LLM's News Article Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b8b22-8017-4b27-9eaa-68385585aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_case = (\n",
    "    \"Generate the taxonomy that can be used to label the news article that would benefit the user.\"\n",
    ")\n",
    "stream = app.stream(\n",
    "    {\"documents\": docs},\n",
    "    {\n",
    "        \"configurable\": {\n",
    "            \"use_case\": use_case,\n",
    "            # Optional:\n",
    "            \"batch_size\": 10,\n",
    "            \"suggestion_length\": 30,\n",
    "            \"cluster_name_length\": 10,\n",
    "            \"cluster_description_length\": 30,\n",
    "            \"explanation_length\": 20,\n",
    "            \"max_num_clusters\": 25,\n",
    "        },\n",
    "        \"max_concurrency\": 2,\n",
    "        \"recursion_limit\": 50,\n",
    "    },\n",
    ")\n",
    "for step in stream:\n",
    "    node, state = next(iter(step.items()))\n",
    "    print(node, str(state)[:20] + \" ...\")\n",
    "from IPython.display import Markdown\n",
    "def format_taxonomy_md(clusters):\n",
    "    md = \"## Final Taxonomy\\\\n\\\\n\"\n",
    "    md += \"| ID | Name | Description |\\\\n\"\n",
    "    md += \"|----|------|-------------|\\\\n\"\n",
    "    # Iterate over each inner list of dictionaries\n",
    "    for cluster_list in clusters:\n",
    "        for label in cluster_list:\n",
    "            id = label[\"id\"]\n",
    "            name = label[\"name\"].replace(\"|\", \"\\\\\\\\|\")  # Escape any pipe characters within the content\n",
    "            description = label[\"description\"].replace(\"|\", \"\\\\\\\\|\")  # Escape any pipe characters\n",
    "            md += f\"| {id} | {name} | {description} |\\\\n\"\n",
    "    return md\n",
    "markdown_table = format_taxonomy_md(step['review_taxonomy']['clusters'])\n",
    "Markdown(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163151a9-b0f1-4e83-9246-a83749d40428",
   "metadata": {},
   "source": [
    "A markdown table with all taxonomies is generated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
